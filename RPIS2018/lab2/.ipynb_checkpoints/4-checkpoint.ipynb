{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([160369, 169896, 180036, 182854, 184145, 186726, 188277, 185186,\n",
       "        181511, 183668, 187006, 188032, 189202, 192534, 189346, 186601,\n",
       "        186186, 188293, 189261, 190701, 191610, 189712, 186670, 186128,\n",
       "        187920, 188636, 189881, 190872, 188092, 185769, 183931, 186458,\n",
       "        189721, 190473, 190433, 189132, 187124, 185986, 186741, 188543,\n",
       "        192034, 192470, 192422, 185576, 192058, 188253, 189281, 191707,\n",
       "        190132, 190064, 190051, 186860, 190061, 190298, 189877, 189301,\n",
       "        191623, 187750, 187812,  46420, 189687, 190022, 187604, 185317,\n",
       "        191264, 188875, 188898, 188729, 187683, 191415, 191429, 190497,\n",
       "        186098, 188761, 186801, 188147, 185039, 190940, 189925, 188654,\n",
       "        188915, 186688, 187888, 189002, 190946, 188913, 187234, 187786,\n",
       "        186601, 186537, 188930, 184953, 189753, 186117, 187181, 183473,\n",
       "        185714, 187594, 188481, 185995, 184427, 184398, 183632, 182379,\n",
       "        187205, 188116, 186258, 184176, 185340, 183308, 183651, 186257,\n",
       "        187468, 185749, 183246, 184090, 183540, 182878, 186262, 184530,\n",
       "        184604, 186051, 184668, 182809, 183080, 187492, 187158, 186358,\n",
       "        184950, 184354, 184927, 186088, 187962, 186466, 186836, 187141,\n",
       "        186458, 185069, 186955, 188870, 192277, 189032, 188540, 188844,\n",
       "        187565, 186477, 186310, 189526, 186866, 188162, 184047, 183882,\n",
       "        190059, 192186, 191331, 189779, 188275, 190874, 187242, 187278,\n",
       "        191371, 184481, 190945, 189850, 186857, 188978, 190019, 183810,\n",
       "        182060, 180100, 190759, 180033, 190047, 191825, 179366, 177928,\n",
       "        174611, 171558, 169983, 168474, 166539, 163857, 189392, 181097,\n",
       "        172823, 173413, 187953, 170630, 186522, 185517, 189878, 189611,\n",
       "        187941, 192309, 187426, 191630, 190104, 189686, 192572, 189024,\n",
       "        187510, 192420, 191065, 191462, 187272, 189416, 189470, 187479,\n",
       "        190549, 191662, 188138, 190974, 184281, 175054, 164918, 157161,\n",
       "        147135, 136201, 124465, 112612, 101889,  88330,  79803,  69052,\n",
       "         57467, 192007, 189130, 191455, 189507, 189785, 192043, 188272,\n",
       "        188307, 191378, 190375, 191067, 189836, 186415, 190673, 192239,\n",
       "        187992, 184771, 183827, 190881, 192313, 188564, 190276, 189947,\n",
       "        191271, 185671, 188988, 188081, 185997, 185877, 188631, 189513,\n",
       "        190177, 187722, 191414, 190528, 186061, 192275, 192309, 191598,\n",
       "        190606, 187753, 186341, 187810, 190993, 185269, 191629, 190600,\n",
       "        192451, 191512, 192328, 191510, 189043, 191054, 192384, 191445,\n",
       "        191381, 188263, 192073, 192357, 186802, 191318, 188165, 186114,\n",
       "        181336, 191059, 190505, 190065, 191314, 190335, 189606, 192410,\n",
       "        190220, 190351, 189774, 191522, 187683, 187413, 191023, 189802,\n",
       "        186512, 189192, 189086, 186953, 186666, 192323, 190339, 191327,\n",
       "        190110, 191365, 185274, 184406, 191641, 189313, 191286, 190061,\n",
       "        190978, 183178, 182066, 180038, 178847, 192033, 184076, 186026,\n",
       "        185885, 185992, 183490, 180462, 183631, 187069, 190619, 178656,\n",
       "        177780, 190340, 188749, 189387, 187322, 188173, 192152, 191753,\n",
       "        191413, 189540, 191652, 187067, 191684, 177152, 172904, 166764,\n",
       "        188818, 183947, 178014, 175517, 186477, 178667, 165050, 153778,\n",
       "        175341, 175457, 174035, 164851, 191435, 177125]),\n",
       " 100000,\n",
       " array([251, 252, 263, 252, 280, 262, 268, 289, 268, 234, 248, 261, 236,\n",
       "        266, 261, 267, 243, 259, 295, 261, 259, 285, 244, 243, 235, 275,\n",
       "        270, 282, 276, 278, 278, 260, 254, 270, 271, 263, 249, 257, 256,\n",
       "        265, 295, 282, 273, 259, 262, 264, 274, 295, 260, 287, 284, 289,\n",
       "        280, 281, 249, 246, 258, 286, 246,  72, 294, 275, 269, 281, 289,\n",
       "        286, 268, 272, 299, 266, 283, 259, 273, 271, 251, 277, 314, 266,\n",
       "        271, 254, 256, 274, 294, 307, 296, 255, 257, 256, 263, 285, 297,\n",
       "        237, 254, 272, 263, 238, 276, 271, 256, 252, 275, 229, 267, 251,\n",
       "        257, 262, 266, 266, 265, 283, 260, 257, 275, 276, 237, 267, 234,\n",
       "        280, 255, 263, 261, 269, 277, 257, 288, 275, 252, 258, 262, 285,\n",
       "        258, 283, 247, 251, 252, 249, 290, 298, 295, 264, 265, 280, 260,\n",
       "        296, 278, 247, 260, 258, 238, 249, 226, 269, 266, 251, 282, 238,\n",
       "        277, 273, 284, 276, 279, 240, 266, 268, 260, 314, 272, 290, 277,\n",
       "        263, 289, 281, 303, 256, 252, 293, 299, 278, 261, 276, 270, 305,\n",
       "        288, 282, 253, 239, 271, 286, 282, 307, 304, 274, 267, 270, 263,\n",
       "        305, 277, 305, 316, 294, 275, 302, 282, 298, 251, 286, 277, 300,\n",
       "        277, 285, 274, 317, 298, 277, 244, 277, 255, 285, 318, 302, 315,\n",
       "        289, 296, 309, 291, 299, 323, 314, 283, 291, 281, 281, 286, 292,\n",
       "        298, 298, 295, 265, 281, 263, 262, 302, 274, 284, 291, 282, 261,\n",
       "        293, 278, 288, 256, 305, 300, 327, 300, 305, 262, 273, 299, 287,\n",
       "        289, 278, 275, 309, 305, 299, 260, 353, 275, 281, 286, 288, 277,\n",
       "        300, 300, 289, 278, 281, 265, 237, 293, 276, 271, 255, 275, 257,\n",
       "        276, 252, 282, 262, 268, 254, 277, 271, 274, 289, 259, 278, 272,\n",
       "        299, 285, 226, 276, 271, 290, 265, 270, 266, 277, 291, 292, 264,\n",
       "        271, 256, 281, 277, 312, 278, 265, 262, 291, 263, 306, 273, 246,\n",
       "        263, 256, 260, 289, 276, 288, 261, 239, 245, 281, 276, 254, 268,\n",
       "        247, 245, 258, 254, 276, 294, 295, 248, 263, 265, 253, 293, 272,\n",
       "        311, 279, 263, 298, 291, 248, 256, 240, 213, 265, 293, 283, 300,\n",
       "        309, 305]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def sample_observed_counts():\n",
    "    # performs bucketing over given table of probabilities\n",
    "    # warning! this function changes the original table\n",
    "    def bucketing(probs):\n",
    "        threshold = np.ones(N) * mean\n",
    "        giver = np.empty(N)\n",
    "\n",
    "        # creating queues of indices of overflowed, and underflowed buckets\n",
    "        condition = probs > mean\n",
    "        over = list(np.where(condition)[0])\n",
    "        under = list(np.where(~condition)[0])\n",
    "\n",
    "        while len(under) and len(over):\n",
    "            take = over.pop()\n",
    "            give = under.pop()\n",
    "\n",
    "            threshold[give] = probs[give]\n",
    "            giver[give] = take\n",
    "            probs[take] -= (mean - probs[give])\n",
    "\n",
    "            diff = probs[take] - mean\n",
    "            if abs(diff) > epsilon:\n",
    "                if diff > 0:\n",
    "                    over.append(take)\n",
    "                else:\n",
    "                    under.append(take)\n",
    "        return threshold, giver\n",
    "\n",
    "\n",
    "    # sampling using the bucketing method\n",
    "    def sample(threshold, second_value, size):\n",
    "        values = np.random.randint(N, size=size)\n",
    "        probs = np.random.sample(size=size) * mean\n",
    "\n",
    "        # for each sampled probability, returns if it's smaller than its threshold\n",
    "        first = probs < threshold[values]\n",
    "\n",
    "        # concatenating table of days that are below threshold with ones that are above threshold\n",
    "        return np.concatenate([values[first], second_value[values[~first]]])\n",
    "\n",
    "\n",
    "    sample_size = 100000\n",
    "    epsilon = 0.001  # calculation accuracy\n",
    "    gross_error = 0.01\n",
    "\n",
    "    _, _, tab = np.loadtxt('us_births_69_88.csv',\n",
    "                           skiprows=1,\n",
    "                           delimiter=',',\n",
    "                           dtype=int,\n",
    "                           unpack=True)\n",
    "\n",
    "    # rejecting the gross error\n",
    "    tab = tab[tab > np.mean(tab) * gross_error]\n",
    "\n",
    "    mean = np.mean(tab)\n",
    "    N = tab.size\n",
    "    \n",
    "    threshold, giver_i = bucketing(tab)\n",
    "\n",
    "    days = sample(threshold, giver_i, sample_size)\n",
    "    \n",
    "    ret = np.bincount(days.astype(int))\n",
    "   \n",
    "    return tab, sample_size, ret\n",
    "    \n",
    "    # end of sampling copied from assignment 2c\n",
    "    \n",
    "\n",
    "sample_observed_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 5b (Testing a sampler).** In this problem we will attempt to check whether the sampler we created in **Problem 2c** works correctly. To this end we will use a chi-squared goodness-of-fit test. This test works as follows:\n",
    " * Let $p_1,\\ldots,p_d$ be the date frequencies as in the text file, scaled down to sum up to 1.\n",
    " * Use the sampler to generate a sample of dates. Let $c_1,\\ldots,c_d$ be the observed counts, and let $f_i=Np_i$ be the expected counts, where $N$ is the sample size. \n",
    " * Compute the test statistic $$S = \\sum_{i=1}^d \\frac{\\left(c_i-f_i\\right)^2}{f_i}.$$\n",
    " * Our base assumption (the null hypothesis) $H_0$ is that our sampler works correctly. If $H_0$ is true AND if the expected count for each bucket is large enough, then $S$ has (approximately) a $\\chi^2$ distribution with $d-1$ degrees of freedom. \n",
    " * Look up how likely is getting an $S$ value as large as the one you obtained if it has that distribution, i.e. the $p$-value. To do this use **scipy.stats.chi2.cdf**. If this value turns out smaller than the assumed threshold, e.g. $0.05$, we reject $H_0$. Otherwise we do not (we support $H_0$), but this does not mean $H_0$ is proved!\n",
    " * We mentioned earlier that expected counts for the buckets need to be large enough. \"Large enough\" assumption here is used to guarantee that $c_i$ are distributed approximately normally. Typically one requires that all counts are at least $5$. This is not the case in our problem (unless we take a huge sample) because of the errors in the data. The typical approach is to glue several buckets into one but this does not help in our case. Instead, ignore the erroneous dates when computing $c_i$ and $f_i$ and run the test again (on the same sample!). Remember to use a different number of degrees of freedom. Compare the results. \n",
    " * Perform the same test using **scipy.stats.chisquare** and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scipy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-48d0083e7e29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# author: Dawid Borys (394094)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mchi2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_observed_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'scipy'"
     ]
    }
   ],
   "source": [
    "# author: Dawid Borys (394094)\n",
    "from scipy.stats import chi2\n",
    "import scipy\n",
    "\n",
    "tab, N, c = sample_observed_counts()\n",
    "\n",
    "print(len(c))\n",
    "\n",
    "p = tab / np.sum(tab)\n",
    "f = N * p\n",
    "\n",
    "S = np.sum(((c - f)**2)/ f)\n",
    "\n",
    "print(\"Computed by me: S = \", S, \" p = \", 1 - chi2.cdf(S, 365))\n",
    "print(scipy.stats.chisquare(c, f))\n",
    "\n",
    "x = np.linspace(230, 500)\n",
    "plt.plot(x, chi2.cdf(x, tab.size))\n",
    "plt.axhline(y=0.95, color='lightgray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
